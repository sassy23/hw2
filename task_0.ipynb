{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-clinic",
   "metadata": {},
   "source": [
    "# Part 0: Dataloader and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import wandb\n",
    "import scipy.io\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from utils import *\n",
    "\n",
    "USE_WANDB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-prague",
   "metadata": {},
   "source": [
    "## Editing the Dataloader\n",
    "The first part of the assignment involves editing the dataloader so that we can access bounding-box proposals as well as the ground-truth bounding boxes. The ground truth bounding box can be accessed through the VOC Dataset annotations itself. Unsupervised bounding box proposals are obtained through methods such as [Selective Search](https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf).\n",
    "\n",
    "Since Selective Search is slow to run on each image, we have pre-computed the bounding box proposals. You should be able to access the `.mat` files using `scipy.io.loadmat('file.mat')`. Feel free to experiment with the data in the files to figure out the number of proposals per image, their scores, etc.\n",
    "\n",
    "Your task is to change the dataloader to obtain the ground-truth bounding boxes, as well as the proposed bounding boxes for each image. Returning a dictionary would be convenient here. For the bounding boxes, using the relative positions is usually a better idea since they are invariant to changes in the size of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset - items at a particular index can be accesed by usual indexing notation (dataset[idx])\n",
    "dataset = VOCDataset('trainval', top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1716210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9804/2819630530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopppy\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopppx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "split = 'trainval'\n",
    "selective_search_dir = os.path.join(\"../data/VOCdevkit/VOC2007/\", 'selective_search_data')\n",
    "roi_data = scipy.io.loadmat(selective_search_dir + '/voc_2007_'+ split + '.mat')\n",
    "\n",
    "\n",
    "\n",
    "# print(roi_data.keys())\n",
    "# print(roi_data['images'].shape)\n",
    "# print(roi_data['images'][:,5])\n",
    "# print(roi_data['boxes'][:,5][0].shape)\n",
    "# print(roi_data['boxScores'][0,10].shape)\n",
    "height = 200.0\n",
    "box = roi_data['boxes'][0,100]\n",
    "box_scores = roi_data['boxScores'][0,100]\n",
    "# print(box_scores)\n",
    "top_n = 10\n",
    "ind = np.argpartition(box_scores, -top_n, axis=0)[-top_n:]\n",
    "# print(ind)\n",
    "# ind = ind[1,0]\n",
    "top = box[ind]\n",
    "# print(top[:,0])\n",
    "# print(top[:,0][:,0])\n",
    "topppy = top[:,0][:,2] \n",
    "# topppy = np.true_divide(topppy, height).reshape(10,1)\n",
    "topppx = top[:,0][:,1] \n",
    "# topppx = np.true_divide(topppx, height).reshape(10,1)\n",
    "# top[:,0][:,0] /= height\n",
    "\n",
    "print(topppy.shape)\n",
    "\n",
    "arr = np.empty((top_n, 1))\n",
    "arr = np.concatenate((arr, topppy/height.reshape(10,1)), axis=1)\n",
    "\n",
    "arr = np.concatenate((arr, topppx/height.reshape(10,1)), axis=1)\n",
    "arr = arr[:,1:]\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confused-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49865952 0.286      0.82841823 0.764     ]\n",
      " [0.00268097 0.862      0.46380697 1.        ]\n",
      " [0.48525469 0.378      0.86058981 0.8       ]\n",
      " [0.31099196 0.254      0.58176944 0.726     ]\n",
      " [0.47453083 0.372      0.89008043 0.726     ]\n",
      " [0.00268097 0.514      0.51474531 0.958     ]\n",
      " [0.51206434 0.372      0.68632708 0.762     ]\n",
      " [0.00268097 0.172      0.57908847 0.962     ]\n",
      " [0.51206434 0.374      0.78552279 0.762     ]\n",
      " [0.00268097 0.374      0.58981233 0.958     ]]\n"
     ]
    }
   ],
   "source": [
    "#TODO: get the image information from index 2020\n",
    "idx = 2020\n",
    "\n",
    "# input = \n",
    "\n",
    "ret = dataset[idx]\n",
    "print(ret['rois'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-recycling",
   "metadata": {},
   "source": [
    "## Wandb Init and Logging\n",
    "Initialize a Weights and Biases project, and convert the image tensor to a PIL image and plot it (check `utils.py` for helper functions).\n",
    "\n",
    "You can use [this](https://docs.wandb.ai/library/log) as a reference for logging syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conventional-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb.init(project=\"vlr2\", reinit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-ladder",
   "metadata": {},
   "source": [
    "See this block as an example of plotting the ground truth box for an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "resistant-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0.])\n",
      "tensor(18)\n",
      "[[0.236, 0.4959785522788204, 0.72, 0.5817694369973191]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A box's class_id must be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10858/3434287476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgt_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m img = wandb.Image(original_image, boxes={\n\u001b[0m\u001b[1;32m     11\u001b[0m     \"predictions\": {\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"box_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_box_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/sdk/data_types.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_or_path, mode, caption, grouping, classes, boxes, masks)\u001b[0m\n\u001b[1;32m   1815\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_initialization_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     def _set_initialization_meta(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/sdk/data_types.py\u001b[0m in \u001b[0;36m_set_initialization_meta\u001b[0;34m(self, grouping, caption, classes, boxes, masks)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                     \u001b[0mboxes_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m                     \u001b[0mboxes_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoundingBoxes2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/sdk/data_types.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, val, key)\u001b[0m\n\u001b[1;32m   1583\u001b[0m                 \u001b[0mThe\u001b[0m \u001b[0mreadable\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbounding\u001b[0m \u001b[0mboxes\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \"\"\"\n\u001b[0;32m-> 1585\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBoundingBoxes2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"box_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/sdk/data_types.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSONMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/wandb/sdk/data_types.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m   1675\u001b[0m                 \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m             ):\n\u001b[0;32m-> 1677\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A box's class_id must be an integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m             \u001b[0;31m# Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: A box's class_id must be an integer"
     ]
    }
   ],
   "source": [
    "class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "original_image = tensor_to_PIL(ret['image'])\n",
    "gt_labels = ret['label']\n",
    "print(gt_labels)\n",
    "gt_labels = np.nonzero(gt_labels)\n",
    "print(gt_labels[0,0])\n",
    "# print(np.nonzero(gt_labels).numpy())\n",
    "gt_boxes = ret['gt_boxes']\n",
    "print(gt_boxes)\n",
    "img = wandb.Image(original_image, boxes={\n",
    "    \"predictions\": {\n",
    "        \"box_data\": get_box_data(gt_labels, gt_boxes),\n",
    "        \"class_labels\": class_id_to_label,\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-thread",
   "metadata": {},
   "source": [
    "Check the `get_box_data` function in `utils.py` and understand how it is being used. Log the image with the GT bounding box on wandb.\n",
    "After, this you should be able to easily plot the top 10 bounding proposals as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "floating-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = ret['rois']\n",
    "nums = range(len(rois)) # placeholder for names of proposals\n",
    "\n",
    "#TODO: plot top ten proposals (of bounding boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
